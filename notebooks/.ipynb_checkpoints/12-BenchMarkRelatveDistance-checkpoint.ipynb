{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from alphabet_detector import AlphabetDetector\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import operator\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../data/comments1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    ad = AlphabetDetector()\n",
    "    res = x\n",
    "    for ch in string.punctuation:                                                                                                     \n",
    "        res = res.replace(ch, ' ')\n",
    "    res = ''.join([i for i in res if not i.isdigit()])\n",
    "    res = res.lower()\n",
    "    res = emoji_pattern.sub(r' ', res)\n",
    "    res = res.replace('\\n', ' ')\n",
    "    res = res.replace('\\t', ' ')\n",
    "    res = res.replace('\\ufeff', ' ')\n",
    "    res = res.replace('\\r\\n', '  ')\n",
    "    res = res.replace('\\xa0', ' ')\n",
    "    res = res.replace('«', ' ')\n",
    "    res = res.replace('»', ' ')\n",
    "    res = res.replace('—', ' ')\n",
    "    res = res.replace('ё', 'е')\n",
    "    res = re.sub(' +',' ', res)\n",
    "    if  not ad.only_alphabet_chars(res, \"CYRILLIC\"): \n",
    "        res = ''\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(clean)\n",
    "df = df[df.text != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('../data/comments_clean1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comments that were manualy labeld\n",
    "manual = pd.read_csv('../data/manual.csv')\n",
    "df = df[~df.id.isin(manual.id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    stemmer = SnowballStemmer(\"russian\", ignore_stopwords=True) \n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    if len(stemmed_word) <= 2:\n",
    "        return word\n",
    "    return stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_bad_words = '../data/bad_words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = open(path_to_bad_words).read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dictionary = [] # array that will contain all bad words\n",
    "stemmed_dictionary = [] # array that will contain actual stems used for finding bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bad_words:\n",
    "    report_dictionary.append(stem(word))\n",
    "    stemmed_dictionary.append(stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_dictionary = [i for i in stemmed_dictionary if len(i) > 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_dictionary.append('хуй') # nltk stemmer can not corectly stem word хуй\n",
    "stemmed_dictionary.append('хуе')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_dictionary = list(set(stemmed_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пиздец',\n",
       " 'заеба',\n",
       " 'ипа',\n",
       " 'хуякнут',\n",
       " 'пердун',\n",
       " 'припизден',\n",
       " 'отъеб',\n",
       " 'пи3д',\n",
       " 'проеба',\n",
       " 'говнян',\n",
       " 'бздех',\n",
       " 'проебанк',\n",
       " 'е6ут',\n",
       " 'хуищ',\n",
       " 'залуп',\n",
       " 'придурок',\n",
       " 'xуе',\n",
       " 'чмыр',\n",
       " 'въебыва',\n",
       " 'похуист',\n",
       " 'распроет',\n",
       " 'елдач',\n",
       " 'ебаньк',\n",
       " 'сран',\n",
       " 'писюн',\n",
       " 'съеба',\n",
       " 'шлюшк',\n",
       " 'мандавошк',\n",
       " 'нехир',\n",
       " 'долбаеб',\n",
       " 'падонк',\n",
       " 'архипиздр',\n",
       " 'ебанут',\n",
       " 'хуйл',\n",
       " 'педерас',\n",
       " 'секел',\n",
       " 'шалав',\n",
       " 'приеба',\n",
       " 'нахр',\n",
       " 'заебист',\n",
       " 'выеба',\n",
       " 'ебн',\n",
       " 'припиздюлин',\n",
       " 'говняк',\n",
       " 'минет',\n",
       " 'сцук',\n",
       " 'припизднут',\n",
       " 'еблищ',\n",
       " 'мудаг',\n",
       " 'хуесоск',\n",
       " 'охует',\n",
       " 'стерв',\n",
       " 'злоеб',\n",
       " 'нех',\n",
       " 'наговня',\n",
       " 'поскуд',\n",
       " 'курвятник',\n",
       " 'ушлепок',\n",
       " 'подонок',\n",
       " 'нихер',\n",
       " 'ибанамат',\n",
       " 'хyё',\n",
       " 'сговня',\n",
       " 'ебут',\n",
       " 'наебыва',\n",
       " 'пезд',\n",
       " 'спиздет',\n",
       " 'ебальник',\n",
       " 'напизд',\n",
       " 'бляб',\n",
       " 'охуел',\n",
       " 'пердунец',\n",
       " 'захуяч',\n",
       " 'нехр',\n",
       " 'уебк',\n",
       " 'хуеньк',\n",
       " 'пиздищ',\n",
       " 'вафел',\n",
       " 'проеб',\n",
       " 'ахует',\n",
       " 'хуюл',\n",
       " 'усра',\n",
       " 'заеб',\n",
       " 'хуек',\n",
       " 'пиздун',\n",
       " 'хуи',\n",
       " 'хуевин',\n",
       " 'пердильник',\n",
       " 'мандищ',\n",
       " 'хуяс',\n",
       " 'хитрожоп',\n",
       " 'отпиздяч',\n",
       " 'бздюх',\n",
       " 'ебатор',\n",
       " 'хыйн',\n",
       " 'лярв',\n",
       " 'напиздел',\n",
       " 'дрочк',\n",
       " 'хyй',\n",
       " 'ниибац',\n",
       " 'лошок',\n",
       " 'уебищ',\n",
       " 'ебаш',\n",
       " 'говнюк',\n",
       " 'пробздел',\n",
       " 'пердет',\n",
       " 'е6ал',\n",
       " 'похуистк',\n",
       " 'ебыч',\n",
       " 'поеба',\n",
       " 'ябыва',\n",
       " 'гандон',\n",
       " 'выебыва',\n",
       " 'минетчик',\n",
       " 'уебищн',\n",
       " 'зае6',\n",
       " 'хуепромышленник',\n",
       " 'быдл',\n",
       " 'блядин',\n",
       " 'педр',\n",
       " 'херов',\n",
       " 'xyй',\n",
       " 'пропиздел',\n",
       " 'херовин',\n",
       " 'пердух',\n",
       " 'сцат',\n",
       " 'ибонех',\n",
       " 'обьеба',\n",
       " 'посра',\n",
       " 'однохуйствен',\n",
       " 'еба',\n",
       " 'пиздарваньчик',\n",
       " 'пиздобрат',\n",
       " 'пидорок',\n",
       " 'заебыва',\n",
       " 'изъебнут',\n",
       " 'блядова',\n",
       " 'выебнул',\n",
       " 'мокрощелк',\n",
       " 'похер',\n",
       " 'херн',\n",
       " 'поебываа',\n",
       " 'мудокли^',\n",
       " 'дрочилк',\n",
       " 'спизд',\n",
       " 'опизденивающ',\n",
       " 'въеб',\n",
       " 'выеб',\n",
       " 'курв',\n",
       " 'пернут',\n",
       " 'хуйрик',\n",
       " 'сцыш',\n",
       " 'взьебыва',\n",
       " 'дрисн',\n",
       " 'взъебк',\n",
       " 'выблядыш',\n",
       " 'бздло',\n",
       " 'пидрас',\n",
       " 'хую',\n",
       " 'шараеб',\n",
       " 'падл',\n",
       " 'сцыкун',\n",
       " 'хуев',\n",
       " 'перднут',\n",
       " 'ебись',\n",
       " 'ебаническ',\n",
       " 'пиздюлин',\n",
       " 'ебан',\n",
       " 'выблядок',\n",
       " 'бздун',\n",
       " 'объебос',\n",
       " 'отпизд',\n",
       " 'гамн',\n",
       " 'пизденк',\n",
       " 'хуевеньк',\n",
       " 'обосца',\n",
       " 'пиздюл',\n",
       " 'сучк',\n",
       " 'говнищ',\n",
       " 'блябуд',\n",
       " 'отпорот',\n",
       " 'дристун',\n",
       " 'мандет',\n",
       " 'охуяньчик',\n",
       " 'потаскушк',\n",
       " 'хитровыеба',\n",
       " 'ниипацц',\n",
       " 'ебическ',\n",
       " 'хуйн',\n",
       " 'обдриста',\n",
       " 'насра',\n",
       " 'хуяк',\n",
       " 'охуен',\n",
       " 'охуяч',\n",
       " 'подъебнут',\n",
       " 'мандавошек',\n",
       " 'пиздет',\n",
       " 'выпердет',\n",
       " 'педик',\n",
       " 'пиздат',\n",
       " 'задрот',\n",
       " 'е6а',\n",
       " 'дриста',\n",
       " 'ебош',\n",
       " 'пердеж',\n",
       " 'промандет',\n",
       " 'бзднут',\n",
       " 'пропиздяч',\n",
       " 'заебаш',\n",
       " 'засира',\n",
       " 'пидарас',\n",
       " 'мраз',\n",
       " 'бздюшк',\n",
       " 'еблив',\n",
       " 'охуева',\n",
       " 'наеба',\n",
       " 'блядищ',\n",
       " 'пезден',\n",
       " 'ебл',\n",
       " 'ебин',\n",
       " 'ебыр',\n",
       " 'сестроеб',\n",
       " 'говнядин',\n",
       " 'въебен',\n",
       " 'трахаеб',\n",
       " 'писюшк',\n",
       " 'подговня',\n",
       " 'серун',\n",
       " 'сук',\n",
       " 'письк',\n",
       " 'ниипет',\n",
       " 'сикел',\n",
       " 'хуеныш',\n",
       " 'пиздобол',\n",
       " 'отмудоха',\n",
       " 'мудозвон',\n",
       " 'доебыва',\n",
       " 'надриста',\n",
       " 'блядун',\n",
       " 'пиздолиз',\n",
       " 'хуеват',\n",
       " 'распиздяйств',\n",
       " 'страхопиздищ',\n",
       " 'запиздяч',\n",
       " 'манден',\n",
       " 'дристух',\n",
       " 'разъеб',\n",
       " 'обьебос',\n",
       " 'спиздел',\n",
       " 'задриста',\n",
       " 'очкун',\n",
       " 'мудист',\n",
       " 'нахер',\n",
       " 'xyёв',\n",
       " 'сыкун',\n",
       " 'сучонок',\n",
       " 'пропиздет',\n",
       " 'елд',\n",
       " 'перден',\n",
       " 'ссыш',\n",
       " 'мудел',\n",
       " 'ниху',\n",
       " 'пизданут',\n",
       " 'въеба',\n",
       " '6лят',\n",
       " 'мудн',\n",
       " 'суч',\n",
       " 'пиздоват',\n",
       " 'злоебуч',\n",
       " 'ебет',\n",
       " 'ебат',\n",
       " 'муд',\n",
       " 'говноед',\n",
       " 'педрилл',\n",
       " 'говен',\n",
       " 'надроч',\n",
       " 'переебок',\n",
       " 'малаф',\n",
       " 'еблыст',\n",
       " 'говешк',\n",
       " 'невъебен',\n",
       " 'говназ',\n",
       " 'настопизд',\n",
       " 'пиздорванец',\n",
       " 'засер',\n",
       " 'пох',\n",
       " 'хуяка',\n",
       " 'сучар',\n",
       " 'взьебк',\n",
       " 'сцан',\n",
       " 'сирыва',\n",
       " 'остоебен',\n",
       " 'потаскух',\n",
       " 'высра',\n",
       " 'ебец',\n",
       " 'заебаст',\n",
       " 'набздел',\n",
       " 'блядств',\n",
       " 'хуер',\n",
       " 'ипацц',\n",
       " 'чмо',\n",
       " 'ебуч',\n",
       " 'петух',\n",
       " 'обосранец',\n",
       " 'заябест',\n",
       " 'xуй',\n",
       " 'бздец',\n",
       " 'гавн',\n",
       " 'елдак',\n",
       " 'уебок',\n",
       " 'хуeм',\n",
       " 'дроч',\n",
       " 'трахател',\n",
       " 'манд',\n",
       " 'хуяч',\n",
       " 'сволоч',\n",
       " 'говнюх',\n",
       " 'разъеба',\n",
       " 'раздолба',\n",
       " 'бара',\n",
       " 'говенк',\n",
       " 'блядк',\n",
       " 'похрен',\n",
       " 'хероват',\n",
       " 'пиздорванк',\n",
       " '6ля',\n",
       " 'хуею',\n",
       " 'охуячива',\n",
       " 'блядюг',\n",
       " 'еблант',\n",
       " 'серьк',\n",
       " 'хер',\n",
       " 'подонк',\n",
       " 'пизд',\n",
       " 'хует',\n",
       " 'высса',\n",
       " 'засрун',\n",
       " 'опезда',\n",
       " 'хуетен',\n",
       " 'ахуел',\n",
       " 'хуерик',\n",
       " 'хуйк',\n",
       " 'пидар',\n",
       " 'педрил',\n",
       " 'ебтвоюма',\n",
       " 'хуел',\n",
       " 'изговня',\n",
       " 'млят',\n",
       " 'хуя',\n",
       " 'говнец',\n",
       " 'наебнут',\n",
       " 'шлюх',\n",
       " '6ляд',\n",
       " 'охуевательск',\n",
       " 'ссак',\n",
       " 'нехуйствен',\n",
       " 'охуительн',\n",
       " 'трахае6',\n",
       " 'мудак',\n",
       " 'пидор',\n",
       " 'бзден',\n",
       " 'гавнючк',\n",
       " 'мудоеб',\n",
       " 'бля',\n",
       " 'охуеньчик',\n",
       " 'ебун',\n",
       " 'поебен',\n",
       " 'пидорас',\n",
       " 'дрочелл',\n",
       " 'урюк',\n",
       " 'вьеб',\n",
       " 'нику',\n",
       " 'ебанныйврот',\n",
       " 'задрачива',\n",
       " 'засера',\n",
       " 'бздит',\n",
       " 'пробляд',\n",
       " 'распиздет',\n",
       " 'гнид',\n",
       " 'xyя',\n",
       " 'сос',\n",
       " 'ебанама',\n",
       " 'говночист',\n",
       " 'говнолинк',\n",
       " 'пиздюг',\n",
       " 'промудет',\n",
       " 'хуё',\n",
       " 'обосра',\n",
       " 'бздет',\n",
       " 'лох',\n",
       " 'жоп',\n",
       " 'замудоха',\n",
       " 'бздиц',\n",
       " 'хуем',\n",
       " 'пипец',\n",
       " 'урод',\n",
       " 'ебёна',\n",
       " 'перданут',\n",
       " 'дрочун',\n",
       " 'педрик',\n",
       " 'нахуйник',\n",
       " 'хуй',\n",
       " 'долбоящер',\n",
       " 'ебущ',\n",
       " 'пидорк',\n",
       " 'сцых',\n",
       " 'заговня',\n",
       " 'сцукон',\n",
       " 'пердунин',\n",
       " 'дрист',\n",
       " 'xую',\n",
       " 'паскуд',\n",
       " 'гомосек',\n",
       " 'пизденыш',\n",
       " 'ебнут',\n",
       " 'целк',\n",
       " 'падонок',\n",
       " 'мудет',\n",
       " 'опизд',\n",
       " 'ублюдок',\n",
       " 'обсира',\n",
       " 'уеба',\n",
       " 'срат',\n",
       " 'гондон',\n",
       " 'хуе',\n",
       " 'говня',\n",
       " 'засерун',\n",
       " 'распизда',\n",
       " 'лошар',\n",
       " 'перд',\n",
       " 'похр',\n",
       " 'ебик',\n",
       " 'ебск',\n",
       " 'хул',\n",
       " 'дристанут',\n",
       " 'вафлер',\n",
       " 'заебош',\n",
       " 'минетчиц',\n",
       " 'пиздострадател',\n",
       " 'сцул',\n",
       " 'мандюк',\n",
       " 'хамл',\n",
       " 'блят',\n",
       " 'выебон',\n",
       " 'долбоеб',\n",
       " 'суходрочк',\n",
       " 'хуесос',\n",
       " 'разхуяч',\n",
       " 'ебла',\n",
       " 'ебанат',\n",
       " 'чмошник',\n",
       " 'срун',\n",
       " 'остопиздет',\n",
       " 'сволот',\n",
       " 'сира',\n",
       " 'говн',\n",
       " 'заебанец',\n",
       " 'пиздяч',\n",
       " 'набздет',\n",
       " 'дрочист',\n",
       " 'пиздюк',\n",
       " 'залупа',\n",
       " 'хуенч',\n",
       " 'хуеплет',\n",
       " 'невротебуч',\n",
       " 'ебар',\n",
       " 'наебет',\n",
       " 'пиздонут',\n",
       " 'гавнюк',\n",
       " 'нах',\n",
       " 'срак',\n",
       " 'ебк',\n",
       " 'бляд',\n",
       " 'хуяр',\n",
       " 'конч',\n",
       " 'распиздя']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label coments with bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    global stemmed_dictionary\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    for bad_word in stemmed_dictionary:\n",
    "        for token in tokens:\n",
    "            if bad_word in token:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.text.apply(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative process of finding new bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word stemming and counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stemmed = dict()\n",
    "for sentence in df.text:\n",
    "    for token in nltk.word_tokenize(sentence):\n",
    "        if token not in all_stemmed:\n",
    "            all_stemmed[token] = stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = dict()\n",
    "for sentence in df.text:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    for token in tokens:\n",
    "        word = stem(token)\n",
    "        if word in all_counts:\n",
    "            all_counts[word] += 1\n",
    "        else:\n",
    "            all_counts[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = dict()\n",
    "for index, row in df.iterrows():\n",
    "    tokens = nltk.word_tokenize(row.text)\n",
    "    for token in tokens:\n",
    "        word = stem(token)\n",
    "        if word in word_to_id:\n",
    "            word_to_id[word].append(row.video_id)\n",
    "        else:\n",
    "            word_to_id[word] = [row.video_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_to_id:\n",
    "    word_to_id[key] = len(list(set(word_to_id[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood of words being in comments labeld as bad or labeld as not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(label):\n",
    "    labeld_part = dict()\n",
    "    part = df[df.label == label]\n",
    "    for index, row in part.iterrows():\n",
    "        sentence = row.text\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        for token in tokens:\n",
    "            stemed = stem(token)\n",
    "            if stemed != '':\n",
    "                if all_counts[stemed] >= 20 and word_to_id[stemed] > 30:\n",
    "                    if stemed in labeld_part:\n",
    "                        labeld_part[stemed] += 1.0/len(part)\n",
    "                    else:\n",
    "                        labeld_part[stemed] = 1.0/len(part)\n",
    "    return labeld_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria functions for decision if word is bad or not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_distance(p_good, p_bad):\n",
    "    difference = dict()\n",
    "    for key in p_good:\n",
    "        if key in p_bad:\n",
    "            difference[key] =(p_bad[key] - p_good[key])/ np.maximum( p_bad[key], p_good[key]) \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logg_odds(p_good, p_bad):\n",
    "    ratio = dict()\n",
    "    for key in p_good:\n",
    "        if key in p_bad:\n",
    "            odds_good =  p_good[key]/(1 -  p_good[key])\n",
    "            odds_bad = p_bad[key]/(1- p_bad[key])\n",
    "            ratio[key] = np.log(odds_bad/odds_good)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(df_bad):\n",
    "    pairs = dict()\n",
    "    for sentence in df_bad.text:\n",
    "        selection = []\n",
    "        for token in nltk.word_tokenize(sentence):\n",
    "            word = stem(token)\n",
    "            if word in stemmed_dictionary and all_counts[word] >= 20:\n",
    "                selection.append(word)\n",
    "        for bad_word in selection:\n",
    "            for token in nltk.word_tokenize(sentence):\n",
    "                word = stem(token)\n",
    "                if bad_word != word and word != '' and all_counts[word] >= 30:\n",
    "                    key = bad_word + '-' + word\n",
    "                    if key in pairs:\n",
    "                        pairs[key] += 1\n",
    "                    else:\n",
    "                        pairs[key] = 1\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi():\n",
    "    bad_likelihood = likelihood(True)\n",
    "    pairs = make_pairs(df[df.label == True])\n",
    "    result = dict()\n",
    "    for key in pairs:\n",
    "        words = key.split('-')\n",
    "        pxy = float(pairs[key]/len(df[df.label == True]))\n",
    "        px = bad_likelihood[words[0]]\n",
    "        py = bad_likelihood[words[1]]\n",
    "        result[key] = np.log(pxy/(px*py))\n",
    "    return result\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining with corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-00b93ae77882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElementTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../corpus/opcorpora.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.5/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \"\"\"\n\u001b[1;32m   1183\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;31m# It can be used to parse the whole source without feeding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                     \u001b[0;31m# it with chunks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_whole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus = xml.etree.ElementTree.parse('../corpus/opcorpora.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_rus_corpus(corpus, word):\n",
    "    for lemma in corpus.iter('lemma'):\n",
    "        found = False\n",
    "        for forms in lemma.getchildren():\n",
    "            if forms.attrib['t'] == word:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting new bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstem(stem):\n",
    "    res = []\n",
    "    for key in all_stemmed:\n",
    "        if all_stemmed[key] == stem:\n",
    "            res.append(key)\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(x, rev = True):\n",
    "    return sorted(x.items(), key=operator.itemgetter(1), reverse=rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dictionary(word):\n",
    "    global stemmed_dictionary\n",
    "    if len(word) <= 2:\n",
    "        return False\n",
    "    #for key in stemmed_dictionary:\n",
    "        #if word in key:\n",
    "            #return False\n",
    "    stemmed_dictionary.append(word)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(df, report_dictionary, stemmed_dictionary):\n",
    "    iter = True\n",
    "    while(iter):\n",
    "        print('-----------------------------------')\n",
    "        print('labeld as abusive: ', len(df[df.label == True]))\n",
    "        #print('List of bad_words')\n",
    "        #print(report_dictionary)\n",
    "        p_bad = likelihood(True)\n",
    "        p_good = likelihood(False)\n",
    "        prob = logg_odds(p_good, p_bad)\n",
    "        print(sort(prob)[:10])\n",
    "        print(prob['майдаун'])\n",
    "        print('New bad words')\n",
    "        new_words = []\n",
    "        for key in prob:\n",
    "            if prob[key] > 1.8:\n",
    "                if update_dictionary(key):\n",
    "                    new_words += unstem(key)\n",
    "                    print(key)\n",
    "        report_dictionary += new_words\n",
    "        if len(new_words) == 0:\n",
    "            iter = False\n",
    "            break\n",
    "        #print('\\nNew dictionary')\n",
    "        #print(report_dictionary)\n",
    "        df['label'] =  df.text.apply(label)\n",
    "        print('relabeld as abusive: ', len(df[df.label == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "labeld as abusive:  13244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bandrusyak/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пошел', 1.8002145672591727), ('член', 1.7052524290952167), ('рот', 1.6989349048094933), ('жрат', 1.6911634139418525), ('что', 1.6063504920715515), ('принцип', 1.5957057586437078), ('безмозгл', 1.544462932425848), ('гнил', 1.531003667241796), ('кита', 1.5298315805916034), ('горет', 1.5173615301984738)]\n",
      "0.5310309305592511\n",
      "New bad words\n",
      "пошел\n",
      "relabeld as abusive:  13278\n",
      "-----------------------------------\n",
      "labeld as abusive:  13278\n",
      "[('член', 1.701576453176969), ('рот', 1.6952443248243876), ('жрат', 1.6874910001853927), ('принцип', 1.6292852399810964), ('что', 1.6033833571059022), ('безмозгл', 1.5407904119005673), ('гнил', 1.5273262350983232), ('горет', 1.5136904781436038), ('тупорыл', 1.4678495851522604), ('квартир', 1.4609205015603532)]\n",
      "0.5273457831878136\n",
      "New bad words\n"
     ]
    }
   ],
   "source": [
    "iterate(df, report_dictionary, stemmed_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['майдаун']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual['evaluation'] = manual.text.apply(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5963488843813387\n",
      "precision:  0.717687074829932\n",
      "recall:  0.6452599388379205\n",
      "f1:  0.679549114331723\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for index, row in manual.iterrows():\n",
    "    if row.label == True and row.evaluation == True:\n",
    "        tp += 1\n",
    "    if row.label == False and row.evaluation == False:\n",
    "        tn += 1\n",
    "    if row.label == False and row.evaluation == True:\n",
    "        fp += 1\n",
    "    if row.label == True and row.evaluation == False:\n",
    "        #print(row.text)\n",
    "        fn += 1\n",
    "accuracy = (tp + fp)/(tp + fp + fn + fp)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1  = 2 * (precision * recall)/(precision + recall)\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
